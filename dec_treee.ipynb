pip install pydotplus


import os

# Add Graphviz to the system's PATH environment variable to allow visualization of decision trees
os.environ["PATH"] += os.pathsep + r'C:\Program Files\Graphviz'

# Importing necessary libraries
from sklearn.tree import DecisionTreeClassifier  # For building the decision tree classifier
from pydotplus import graph_from_dot_data  # For generating the graphical representation of the decision tree
from sklearn.tree import export_graphviz  # For exporting the decision tree in DOT format (graph description language)


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier

# Loading dataset
df = pd.read_csv('Iris.csv')  # Read the Iris dataset CSV
df.drop('Id', axis=1, inplace=True)  # Drop the 'Id' column which is not necessary for classification

# Separating features (X_) and target (Y_)
X_ = df.iloc[:, :-1]  # All rows, excluding the last column (features)
Y_ = df.iloc[:, -1]  # All rows, last column (target - species)

print(df)

# Splitting data into training and testing sets (70% training, 30% testing)
X_train, X_test, Y_train, Y_test = train_test_split(X_, Y_, test_size=0.3, random_state=1)
print(df)

# Decision Tree Classifier

import os
# Adding Graphviz to the system path for visualization
os.environ["PATH"] += os.pathsep + r"C:\Program Files\Graphviz"

from pydotplus import graph_from_dot_data  # For converting the tree to a graph
from sklearn.tree import export_graphviz  # For exporting the decision tree in DOT format

# Setting minimum samples required to split a node
min_sample_ = 30  # You can experiment with this value to observe the effect on the tree

# Initializing the DecisionTreeClassifier with 'entropy' as the splitting criterion
tree = DecisionTreeClassifier(criterion='entropy',
                              min_samples_split=min_sample_,  # Minimum samples required to split a node
                              random_state=1)  # Setting random_state for reproducibility

# Training the decision tree on the training set
tree.fit(X_train, Y_train)

# Exporting the trained decision tree to DOT format
dot_data = export_graphviz(tree,
                           filled=True,  # Fill the nodes with colors to indicate classes
                           rounded=True,  # Make the nodes rounded
                           class_names=['Setosa', 'Versicolor', 'Virginica'],  # Class names in the target
                           feature_names=['SepalLengthCm', 'Sepal Width', 'Petal Length', 'Petal Width'],  # Feature names
                           out_file=None)  # Do not write to a file, keep it in a string

# Converting the DOT data to a graph
graph = graph_from_dot_data(dot_data)

# Saving the graph as a PNG file
graph.write_png('split_tree_{}.png'.format(min_sample_))  # Save as PNG image with dynamic file name based on min_samples_split


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier

# Load the Iris dataset
df = pd.read_csv('Iris.csv')
df.drop('Id', axis=1, inplace=True)  # Drop the 'Id' column (as it is not needed)

# Define features (X) and target (Y)
X_ = df.iloc[:, :-1]  # All rows and all columns except the last column (features)
Y_ = df.iloc[:, -1]   # The last column (target)

# Print the first few rows and shape of the dataset
print(df)
print(f"Shape of the dataset: {df.shape}")

# Split the dataset into training and testing sets (80% train, 20% test)
X_train, X_test, Y_train, Y_test = train_test_split(X_, Y_, test_size=0.3, random_state=1)

# Print shapes of the training and testing data
print(f"Training features shape: {X_train.shape}")
print(f"Testing features shape: {X_test.shape}")

# Decision Tree Classifier setup
import os
# Set the path to Graphviz executable folder (NOT the installer file, it should be the directory where Graphviz executables are located)
# For example: r'C:\Program Files\Graphviz\bin' or the correct path on your system
os.environ["PATH"] += os.pathsep + r'C:\Program Files\Graphviz\bin'

from sklearn.tree import DecisionTreeClassifier
from pydotplus import graph_from_dot_data
from sklearn.tree import export_graphviz

# Define the decision tree classifier with entropy criterion
min_sample_ = 30
tree = DecisionTreeClassifier(criterion='entropy', min_samples_split=min_sample_, random_state=1)

# Fit the model to the training data
tree.fit(X_train, Y_train)

# Export the tree to DOT format and create a visualization
dot_data = export_graphviz(tree,
                           filled=True,
                           rounded=True,
                           class_names=['Setosa', 'Versicolor', 'Virginica'],
                           feature_names=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'],
                           out_file=None)

# Generate the graph from DOT data and save it as a PNG image
graph = graph_from_dot_data(dot_data)
graph.write_png('decision_tree.png')

# If you want to visualize the tree inline (in Jupyter notebooks or similar), use the following:
# from IPython.display import Image
# Image('decision_tree.png')

# Display the plot showing the tree's structure
plt.imshow(plt.imread('decision_tree.png'))
plt.axis('off')  # Turn off axes
plt.show()


# Minimum number of samples required to split a node
min_sample_ = 30

# Initialize the DecisionTreeClassifier with entropy criterion and min_samples_split parameter
tree = DecisionTreeClassifier(criterion='entropy',
                              min_samples_split=min_sample_,
                              random_state=1)

# Fit the model on the training data
tree.fit(X_train, Y_train)

# Export the trained decision tree model to DOT format
dot_data = export_graphviz(tree,
                           filled=True,               # Nodes will be filled with colors
                           rounded=True,              # Rounded corners for the nodes
                           class_names=['Setosa', 'Versicolor', 'Virginica'],  # Target class names
                           feature_names=['SepalLengthCm', 'Sepal Width', 'petal lenght', 'petal width'],  # Feature names
                           out_file=None)  # Do not save to file, return the data as a string

# Convert the DOT data to a graph object
graph = graph_from_dot_data(dot_data)

# Write the graph to a PNG file with the name based on min_sample_
graph.write_png('split_tree_{}.png'.format(min_sample_))


from sklearn.metrics import accuracy_score  # Importing accuracy_score to evaluate model performance

# Initial prediction with the previously trained tree (for reference)
predict_ = tree.predict(X_test)

# List to store accuracy for different tree depths
y = []

# Loop through different values of max_depth for the decision tree
for i in range(1, 5):
    # Train a new decision tree with 'entropy' criterion and varying max_depth
    tree = DecisionTreeClassifier(criterion='entropy', max_depth=i, random_state=1)
    tree.fit(X_train, Y_train)  # Fit the model to the training data
    predict_ = tree.predict(X_test)  # Make predictions on the test set

    # Calculate accuracy and append it to the list 'y'
    acc = accuracy_score(Y_test, predict_) * 100  # Multiply by 100 to get percentage
    y.append(acc)

# Plotting the accuracy for different values of max_depth
plt.plot(range(1, 5), y, '-o', c='blue')  # Plot accuracy vs tree depth
plt.title("Accuracy of Decision Tree Classifier with Varying Depth")
plt.xlabel("Max Depth")
plt.ylabel("Accuracy (%)")
plt.show()
